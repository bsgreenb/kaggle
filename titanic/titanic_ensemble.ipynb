{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation:\n",
      "\n",
      "ROC AUC: 0.82 (+/- 0.03) [XGBoost]\n",
      "ROC AUC: 0.68 (+/- 0.03) [Logistic regression]\n",
      "ROC AUC: 0.68 (+/- 0.03) [KNN]\n",
      "Accuracy: 0.82 (+/- 0.03) [XGBoost]\n",
      "Accuracy: 0.68 (+/- 0.03) [Logistic regression]\n",
      "Accuracy: 0.68 (+/- 0.03) [KNN]\n",
      "Accuracy: 0.68 (+/- 0.03) [Voting-hard]\n",
      "Accuracy: 0.83 (+/- 0.03) [Voting-soft]\n"
     ]
    }
   ],
   "source": [
    "# Following section in book: Using the majority voting principle to make predictions\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def feature_eng(data):\n",
    "    data['Embarked'].fillna(data['Embarked'].mode()[0], inplace = True)\n",
    "    data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n",
    "    eng_title(data)\n",
    "    eng_age(data)\n",
    "\n",
    "def eng_title(data):\n",
    "    data['Title']=0\n",
    "    data['Title']=data.Name.str.extract('([A-Za-z]+)\\.') #lets extract the Salutations\n",
    "    data['Title'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Dona','Jonkheer','Col',\n",
    "                         'Rev','Capt','Sir','Don'],['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr'],inplace=True)\n",
    "\n",
    "def eng_age(data):\n",
    "    data.loc[(data.Age.isnull())&(data.Title=='Mr'),'Age']= data.Age[data.Title==\"Mr\"].mean()\n",
    "    data.loc[(data.Age.isnull())&(data.Title=='Mrs'),'Age']= data.Age[data.Title==\"Mrs\"].mean()\n",
    "    data.loc[(data.Age.isnull())&(data.Title=='Master'),'Age']= data.Age[data.Title==\"Master\"].mean()\n",
    "    data.loc[(data.Age.isnull())&(data.Title=='Miss'),'Age']= data.Age[data.Title==\"Miss\"].mean()\n",
    "    data.loc[(data.Age.isnull())&(data.Title=='Other'),'Age']= data.Age[data.Title==\"Other\"].mean()\n",
    "\n",
    "\n",
    "train_data = pd.read_csv('train.csv')\n",
    "feature_eng(train_data)\n",
    "\n",
    "test_data = pd.read_csv('test.csv')\n",
    "feature_eng(test_data)\n",
    "\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'FamilySize', 'Fare', 'Embarked']\n",
    "\n",
    "X_train = train_data[features]\n",
    "y_train = train_data['Survived']\n",
    "\n",
    "X_test = test_data[features]\n",
    "\n",
    "X_train = pd.get_dummies(X_train)\n",
    "X_test = pd.get_dummies(X_test)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, stratify=y_train, random_state=1)\n",
    "\n",
    "# No need to scale this guy.\n",
    "clf1 = xgb.XGBClassifier(max_depth=4, learning_rate=.01, n_estimators=300,random_state=1)\n",
    "\n",
    "clf2 = LogisticRegression(penalty='l2', C=0.001,solver='lbfgs',random_state=1)\n",
    "pipe2 = Pipeline([['sc', StandardScaler()], ['clf', clf2]])\n",
    "\n",
    "clf3 = KNeighborsClassifier(n_neighbors=1,p=2,metric='minkowski')\n",
    "pipe3 = Pipeline([['sc', StandardScaler()], ['clf', clf2]])\n",
    "\n",
    "clf_labels = ['XGBoost', 'Logistic regression', 'KNN']\n",
    "\n",
    "print('10-fold cross validation:\\n')\n",
    "#TODO: understand python zip\n",
    "for clf, label in zip([clf1, pipe2, pipe3], clf_labels):\n",
    "    #TODO: try to with both accuracy and ROC/AUC scoring\n",
    "    scores = cross_val_score(estimator=clf,X=X_train,y=y_train,cv=10,scoring='accuracy')\n",
    "    print(f'ROC AUC: {scores.mean():.2f} '\n",
    "    f'(+/- {scores.std():.2f}) [{label}]')\n",
    "\n",
    "\n",
    "\n",
    "mv_hard_clf = VotingClassifier(estimators=list(zip(clf_labels, [clf1, pipe2, pipe3])), voting='hard')\n",
    "mv_soft_clf = VotingClassifier(estimators=list(zip(clf_labels, [clf1, pipe2, pipe3])), voting='soft')\n",
    "\n",
    "#use mv_clf.get_params() to see what parameters you can optimize\n",
    "clf_labels += ['Voting-hard', 'Voting-soft']\n",
    "all_clf = [clf1, pipe2, pipe3, mv_hard_clf, mv_soft_clf]\n",
    "\n",
    "for clf, label in zip(all_clf, clf_labels):\n",
    "    scores = cross_val_score(estimator=clf, X=X_train,y=y_train,cv=10, scoring='accuracy')\n",
    "    print(f'Accuracy: {scores.mean():.2f} ' f'(+/- {scores.std():.2f}) [{label}]')\n",
    "\n",
    "# #TODO: write to CSV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
