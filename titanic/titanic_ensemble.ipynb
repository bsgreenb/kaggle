{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Pclass      418 non-null    int64  \n",
      " 1   Age         418 non-null    float64\n",
      " 2   SibSp       418 non-null    int64  \n",
      " 3   Parch       418 non-null    int64  \n",
      " 4   FamilySize  418 non-null    int64  \n",
      " 5   Fare        418 non-null    float64\n",
      " 6   Sex_female  418 non-null    bool   \n",
      " 7   Sex_male    418 non-null    bool   \n",
      " 8   Embarked_C  418 non-null    bool   \n",
      " 9   Embarked_Q  418 non-null    bool   \n",
      " 10  Embarked_S  418 non-null    bool   \n",
      "dtypes: bool(5), float64(2), int64(4)\n",
      "memory usage: 21.8 KB\n",
      "Accuracy: 0.82 (+/- 0.03) [XGBoost]\n",
      "Accuracy: 0.68 (+/- 0.03) [Logistic regression]\n",
      "Accuracy: 0.80 (+/- 0.03) [KNN]\n",
      "Accuracy: 0.80 (+/- 0.04) [LinearSVC]\n",
      "Accuracy: 0.80 (+/- 0.05) [RandomForest]\n",
      "Accuracy: 0.80 (+/- 0.03) [GaussianNB]\n",
      "Accuracy: 0.80 (+/- 0.04) [Voting-hard]\n",
      "Accuracy: 0.81 (+/- 0.03) [Voting-soft]\n"
     ]
    }
   ],
   "source": [
    "# Following section in book: Using the majority voting principle to make predictions\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def feature_eng(data):\n",
    "    data['Embarked'].fillna(data['Embarked'].mode()[0], inplace = True)\n",
    "    data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n",
    "    data['Fare'].fillna(data['Fare'].mean(),inplace=True)\n",
    "    eng_title(data)\n",
    "    eng_age(data)\n",
    "\n",
    "def eng_title(data):\n",
    "    data['Title']=0\n",
    "    data['Title']=data.Name.str.extract('([A-Za-z]+)\\.') #lets extract the Salutations\n",
    "    data['Title'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Dona','Jonkheer','Col',\n",
    "                         'Rev','Capt','Sir','Don'],['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr'],inplace=True)\n",
    "\n",
    "def eng_age(data):\n",
    "    data.loc[(data.Age.isnull())&(data.Title=='Mr'),'Age']= data.Age[data.Title==\"Mr\"].mean()\n",
    "    data.loc[(data.Age.isnull())&(data.Title=='Mrs'),'Age']= data.Age[data.Title==\"Mrs\"].mean()\n",
    "    data.loc[(data.Age.isnull())&(data.Title=='Master'),'Age']= data.Age[data.Title==\"Master\"].mean()\n",
    "    data.loc[(data.Age.isnull())&(data.Title=='Miss'),'Age']= data.Age[data.Title==\"Miss\"].mean()\n",
    "    data.loc[(data.Age.isnull())&(data.Title=='Other'),'Age']= data.Age[data.Title==\"Other\"].mean()\n",
    "\n",
    "\n",
    "train_data = pd.read_csv('train.csv')\n",
    "feature_eng(train_data)\n",
    "\n",
    "test_data = pd.read_csv('test.csv')\n",
    "feature_eng(test_data)\n",
    "\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'FamilySize', 'Fare', 'Embarked']\n",
    "\n",
    "X_train_orig = train_data[features]\n",
    "y_train_orig = train_data['Survived']\n",
    "\n",
    "X_test = test_data[features]\n",
    "\n",
    "X_train_orig = pd.get_dummies(X_train_orig)\n",
    "X_test = pd.get_dummies(X_test)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_orig, y_train_orig, stratify=y_train_orig, random_state=1)\n",
    "\n",
    "# No need to scale this guy.\n",
    "clf1 = xgb.XGBClassifier(max_depth=4, learning_rate=.01, n_estimators=300,random_state=1)\n",
    "\n",
    "clf2 = LogisticRegression(penalty='l2', C=0.001,solver='lbfgs',random_state=1)\n",
    "pipe2 = Pipeline([['sc', StandardScaler()], ['clf', clf2]])\n",
    "\n",
    "clf3 = KNeighborsClassifier(algorithm='auto', leaf_size=26, metric='minkowski', \n",
    "                           metric_params=None, n_neighbors=6, p=2, \n",
    "                           weights='uniform')\n",
    "pipe3 = Pipeline([['sc', StandardScaler()], ['clf', clf3]])\n",
    "\n",
    "clf4 = LinearSVC(random_state=1, C=0.1, max_iter=100000, dual='auto')\n",
    "pipe4 = Pipeline([['sc', StandardScaler()], ['clf', clf4]])\n",
    "\n",
    "clf5 = RandomForestClassifier(random_state=1, n_estimators=350, max_features=3)\n",
    "\n",
    "clf6 = GaussianNB()\n",
    "pipe6 = Pipeline([['sc', StandardScaler()], ['clf', clf6]])\n",
    "\n",
    "clf_labels = ['XGBoost', 'Logistic regression', 'KNN', 'LinearSVC', 'RandomForest', 'GaussianNB']\n",
    "\n",
    "all_clf = [clf1, pipe2, pipe3, pipe4, clf5, pipe6]\n",
    "\n",
    "\n",
    "mv_hard_clf = VotingClassifier(estimators=list(zip(clf_labels, all_clf)), voting='hard')\n",
    "soft_clf = [clf1,pipe2,pipe3,clf5,pipe6]\n",
    "mv_soft_clf = VotingClassifier(estimators=list(zip(clf_labels, soft_clf)), voting='soft')\n",
    "\n",
    "#use mv_clf.get_params() to see what parameters you can optimize\n",
    "clf_labels += ['Voting-hard', 'Voting-soft']\n",
    "all_clf += [mv_hard_clf,mv_soft_clf]\n",
    "\n",
    "for clf, label in zip(all_clf, clf_labels):\n",
    "    scores = cross_val_score(estimator=clf, X=X_train,y=y_train,cv=10, scoring='accuracy')\n",
    "    print(f'Accuracy: {scores.mean():.2f} ' f'(+/- {scores.std():.2f}) [{label}]')\n",
    "\n",
    "mv_hard_clf.fit(X_train_orig, y_train_orig)\n",
    "predictions = mv_hard_clf.predict(X_test)\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('submission_ensemble_hard.csv', index=False)\n",
    "\n",
    "# #TODO: write to CSV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
